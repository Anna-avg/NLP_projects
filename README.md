# NLP кластеризация и классификация
Этот репозиторий содержит описание моих основных проектов по NLP и [ссылку](https://drive.google.com/drive/folders/1ettjb4d9GFTEFIhbZdlSbo0C263DvIDJ?usp=sharing) на папку со всеми материалами. Ниже Вы найдете краткое описание процесса обучения моделей и удачных решений, которые помогли достичь результата. Если Вы хотите подробнее ознакомиться с проектами, то можете посмотреть [видео](https://drive.google.com/file/d/1wG92rvFOFZSeF1A2-Zuy1LoX_jcq2izt/view?usp=sharing) работы всей системы или ноутбуки, которые я делала по ходу работы.

1. Проект по кластеризации содержит [видео](https://drive.google.com/file/d/1wG92rvFOFZSeF1A2-Zuy1LoX_jcq2izt/view?usp=sharing) работы дообученной модели, встроенной в интерфейс, [презентацию](https://docs.google.com/presentation/d/14bHkHukzEUTDXHRx4GLitxt88h8qq1K-/edit?usp=sharing&ouid=117838439225299978178&rtpof=true&sd=true) сравнение результатов модели до/после обучения, [ipynb](https://drive.google.com/file/d/1GDfE2sXZiWtjiVcXzKdmhH8PtbWXAODx/view?usp=sharing) файл с алгоритмом обучения и предобработкой текстов.

   Проект по созданию системы для кластеризации текстов СМИ, который может сократить работу каждого специалиста по мониторингу СМИ и соц. сетей примерно в 2 раза. Для того, чтобы этого достичь я решила оптимизировать процесс на 3 уровнях:
  - дообучение модели на кастомном датасете;
  - модификация алгоритма кластеризации текстов DBscan;
  - архитектурное решение в интерфейсе, позволяющее невелировать возможные неточности модели.

    Дообучение модели "Название" проводила с помощью датасета, который я вытащила с помощью SQL запроса из внутренней базы данных PostgresSQL. Датасет состоит из текстов инфополя определенной тематики, с которой модель будет взаимодейтсоввать вполследствии. Обучение проводила на  3 275 тематиках. Каждый текст был разбит на предложения и предложения одной тематики были противопоставлены всем остальным тематикам, т.к. использовался AllTripletLoss. Всего семплов в выборке -  460 428. По итогам первой эпохи значение лосса составило 1,68 и далее он не уменьшался, таким образом первая эпоха модели была выбрана для дальнейшей работы. Поскольку для алгоритмов кластеризации на данный момент нет универсальных метрик качества кроме лосса модели, то я отобрала сеты из текстов, чтобы посмотреть работу модели на реальных данных. В сеты текстов закладывала следующие критерии: степень перифраза - модель должна справляться не только с дублями текстов и определять их в одну тематику, но и тексты с высокой степенью перефразированности, разнообразие тематик - даже если тематик много модель должна относить сходие тексты к своим кластерам, длина текстов. Таким образом, я сформулировала и определила свои метрики качества работы модели. После обучения модель справилась с кластеризацией и удовлетворила всем критеряим. Сравнение распределение по кластерам ДО и ПОСЛЕ обучения можно посмотреть в презентации.
    
    Модификация алгоритма заключалась в том, что перед подачей текстов длинные тексты я обрубала до 512 слов, по 256 слов с каждой стороны от названия компании-заказчика. Таким образом, контекст связанный с компанией-заказчиком с наибольшей долей вероятности останется для распределения DBscan-ом, а лишний контектс (фоновые упоминания комапнии-заказчика в статьях) уйдет. А короткие тексты я дублирровала до 512 слов, поскольку если тексты были слишком длинные или слишком короткие, то алгоритм автоматически распределял их в отдельнные кластеры вне зависимости от контекста. Таким образом, я повысила вероятность распределения текста в нужный кластер до токенизации.
    
    В ходе проверок качества работы модели я выяснила, что у нее есть ограничения - если событие одно, но схожего контекста мало, то она будет распрделеять тексты в разные кластеры, а не в один, как хотелось бы. Для того, чтобы невилировать этот недостаток при проектировании логики работы интерфейса я заложило возможность "перетаскивания" статей из одного кластера в другой зажатием мыши. Этот функционал хорошо видно на видео. Чтобы при работе с большими массивами текстов, имеющих мало общего контекста, или если пользователь видит иное распределение кластеров, то их можно было дораспределить вручную.
     
2. Классификация нарративов - файл с EDA, предобработкой данных и несколькоми вариантами обучения модели на задачу многоклассовой классификации.

   Автоматическое определение нарративов поможет команде быстрее определять нарративы и может оптимизировать процесс разметки и анализа текстов. Из 18 классов 13 дали F1 больше 80, еще 4 класса - больше 70. В данном случае не только точность, но и полнота классов имеет большое значение.  Методы, позволившие добиться хороших результатов:
   - тщательное утсранение "шума" в признаковом пространстве;
   - разделение данных и эксперименты со структурой датасета.

     До выполнения EDA анализа я изучила тексты и, чтобы дать модели максимально точно представление и наборе признаков, относящихся к каждому нарративу, и выбросила все тексты-авторасшифровки и тексты длинее 2 000 слов. Я предположила, что слишком длинные тексты содержат фновые упоминания организации, транслирующей нарративы, поэтому они не привнесут ничего полезного в обучение. Авторасшифровки, как правило, содержат ломанные предложения и урывки тексты, котоые сложно связать между собой. Соответственно, они тоже не привносят ничего нового и не помогают при обучении классификации.

      Заметив, что в датасете есть тексты с 1 нарративом и с 2 и более, я разнесла эти данные в отдельные датасеты. Взяла датасет с 1 нарративом на текст, обрезала его по минимально возможным значениям классов и аугментировала классы с недостотачным колличеством нарративов, что привело к высоким метрикам модели во время обучения.
